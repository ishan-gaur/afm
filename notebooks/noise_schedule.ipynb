{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f760e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "s = \"\".join([\"HELLOTHERE\" * 3])\n",
    "s_ascii = [ord(c) for c in s]\n",
    "\n",
    "D = len(s)\n",
    "T = 12\n",
    "t_T = np.random.random(T)\n",
    "t_T = np.sort(t_T)\n",
    "t_T[0] = 0.0\n",
    "t_T[-1] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1066fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S' 'O' 'X' 'F' 'N' 'H' 'L' 'J' 'Q' 'W' 'L' 'R' 'U' 'Q' 'Y' 'G' 'Q' 'F'\n",
      "  'U' 'J' 'G' 'D' 'C' 'P' 'M' 'R' 'B' 'I' 'E' 'R']\n",
      " ['D' 'X' 'Q' 'B' 'S' 'F' 'W' 'S' 'E' 'J' 'V' 'G' 'W' 'L' 'V' 'E' 'P' 'W'\n",
      "  'X' 'A' 'L' 'V' 'O' 'Z' 'T' 'U' 'D' 'E' 'A' 'X']\n",
      " ['X' 'Q' 'T' 'S' 'O' 'I' 'H' 'D' 'O' 'J' 'C' 'D' 'H' 'H' 'W' 'T' 'P' 'W'\n",
      "  'L' 'E' 'E' 'W' 'H' 'P' 'U' 'Q' 'H' 'P' 'T' 'X']\n",
      " ['H' 'W' 'Y' 'B' 'W' 'N' 'G' 'E' 'R' 'X' 'X' 'Y' 'M' 'M' 'F' 'R' 'W' 'I'\n",
      "  'Q' 'M' 'U' 'N' 'C' 'A' 'N' 'T' 'H' 'E' 'C' 'E']\n",
      " ['H' 'E' 'L' 'A' 'O' 'P' 'I' 'P' 'R' 'E' 'H' 'I' 'N' 'L' 'Y' 'N' 'H' 'E'\n",
      "  'O' 'E' 'H' 'E' 'H' 'L' 'O' 'T' 'K' 'W' 'Z' 'W']\n",
      " ['H' 'E' 'L' 'L' 'Q' 'T' 'Y' 'E' 'R' 'E' 'K' 'G' 'L' 'L' 'C' 'T' 'U' 'A'\n",
      "  'R' 'E' 'H' 'E' 'L' 'V' 'F' 'T' 'H' 'A' 'I' 'E']\n",
      " ['H' 'E' 'L' 'L' 'J' 'T' 'H' 'J' 'R' 'E' 'H' 'E' 'Z' 'K' 'O' 'T' 'K' 'E'\n",
      "  'R' 'E' 'H' 'E' 'L' 'F' 'O' 'T' 'H' 'E' 'R' 'E']\n",
      " ['H' 'E' 'L' 'L' 'O' 'M' 'H' 'E' 'E' 'E' 'M' 'E' 'L' 'L' 'O' 'V' 'H' 'E'\n",
      "  'R' 'E' 'H' 'E' 'X' 'L' 'O' 'T' 'H' 'E' 'R' 'E']\n",
      " ['H' 'E' 'L' 'L' 'O' 'C' 'D' 'E' 'U' 'E' 'H' 'E' 'F' 'L' 'O' 'T' 'H' 'E'\n",
      "  'T' 'E' 'H' 'E' 'B' 'L' 'O' 'F' 'H' 'E' 'R' 'R']\n",
      " ['H' 'E' 'L' 'L' 'O' 'T' 'O' 'E' 'R' 'E' 'H' 'E' 'L' 'L' 'O' 'G' 'H' 'E'\n",
      "  'R' 'E' 'H' 'E' 'L' 'C' 'O' 'T' 'H' 'T' 'R' 'E']\n",
      " ['H' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'M' 'E' 'H' 'E' 'L' 'L' 'O' 'T' 'H' 'E'\n",
      "  'R' 'E' 'H' 'E' 'S' 'L' 'O' 'T' 'H' 'E' 'R' 'E']\n",
      " ['H' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'R' 'E' 'H' 'E' 'L' 'L' 'O' 'T' 'H' 'E'\n",
      "  'R' 'E' 'H' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'R' 'E']]\n"
     ]
    }
   ],
   "source": [
    "p_sample_uniform_TD = np.tile((1 - t_T).reshape(-1, 1), (1, D))\n",
    "rand_TD = np.random.random((T, D))\n",
    "\n",
    "s_ascii_mutated_TD = np.where(\n",
    "    rand_TD < p_sample_uniform_TD, \n",
    "    np.random.randint(ord(\"A\"), ord(\"Z\") + 1, (T, D)), \n",
    "    s_ascii\n",
    ")\n",
    "\n",
    "s_mutated_TD = np.array([chr(c) for c in s_ascii_mutated_TD.flatten()]).reshape(T, D)\n",
    "print(s_mutated_TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' '\n",
      "  ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' 'T' ' ' ' '\n",
      "  ' ' ' ' ' ' 'E' ' ' ' ' 'O' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ' 'T' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' '\n",
      "  'R' ' ' ' ' 'E' 'L' ' ' 'O' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' 'L' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' 'L' ' ' ' ' ' ' ' '\n",
      "  ' ' ' ' ' ' ' ' ' ' ' ' 'O' ' ' ' ' ' ' ' ' ' ']\n",
      " [' ' 'E' ' ' 'L' ' ' 'T' ' ' ' ' 'R' ' ' 'H' 'E' 'L' 'L' ' ' ' ' ' ' ' '\n",
      "  ' ' ' ' 'H' 'E' 'L' ' ' 'O' ' ' 'H' 'E' 'R' ' ']\n",
      " ['H' 'E' 'L' 'L' ' ' 'T' ' ' ' ' 'R' ' ' 'H' 'E' 'L' 'L' 'O' 'T' 'H' 'E'\n",
      "  ' ' ' ' 'H' 'E' ' ' 'L' ' ' 'T' 'H' ' ' 'R' ' ']\n",
      " ['H' 'E' ' ' ' ' 'O' 'T' 'H' 'E' 'R' 'E' ' ' ' ' 'L' 'L' 'O' 'T' ' ' ' '\n",
      "  'R' 'E' 'H' ' ' ' ' 'L' 'O' 'T' ' ' ' ' 'R' ' ']\n",
      " ['H' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'R' 'E' 'H' 'E' 'L' ' ' 'O' 'T' ' ' 'E'\n",
      "  'R' 'E' 'H' 'E' ' ' 'L' 'O' ' ' ' ' 'E' 'R' 'E']\n",
      " ['H' 'E' ' ' 'L' 'O' 'T' 'H' 'E' 'R' ' ' 'H' 'E' ' ' ' ' 'O' 'T' 'H' ' '\n",
      "  'R' 'E' 'H' 'E' 'L' ' ' ' ' ' ' 'H' 'E' 'R' 'E']\n",
      " [' ' 'E' 'L' 'L' ' ' 'T' 'H' 'E' ' ' ' ' 'H' 'E' 'L' 'L' 'O' ' ' ' ' 'E'\n",
      "  'R' 'E' ' ' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'R' 'E']\n",
      " [' ' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'R' 'E' 'H' 'E' 'L' ' ' 'O' 'T' 'H' 'E'\n",
      "  'R' 'E' 'H' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'R' 'E']\n",
      " ['H' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'R' 'E' 'H' 'E' 'L' 'L' 'O' 'T' 'H' 'E'\n",
      "  'R' 'E' 'H' 'E' 'L' 'L' 'O' 'T' 'H' 'E' 'R' 'E']]\n"
     ]
    }
   ],
   "source": [
    "p_sample_delete_TD = np.tile((1 - t_T).reshape(-1, 1), (1, D))\n",
    "rand_TD = np.random.random((T, D))\n",
    "\n",
    "s_ascii_deleted_TD = np.where(\n",
    "    rand_TD < p_sample_delete_TD, \n",
    "    32,\n",
    "    s_ascii\n",
    ")\n",
    "\n",
    "s_deleted_TD = np.array([chr(c) for c in s_ascii_deleted_TD.flatten()]).reshape(T, D)\n",
    "print(s_deleted_TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9a829f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.145, 0.563, 0.218, 2.675, 2.671, 2.402, 3.029, 2.663, 2.365, 2.165, 0.0]\n",
      "[0, 3, 5, 3, 15, 20, 19, 25, 22, 23, 28, 30]\n",
      "[0, 0.04833333333333333, 0.11259999999999999, 0.07266666666666667, 0.17833333333333332, 0.13355, 0.12642105263157896, 0.12115999999999999, 0.12104545454545454, 0.10282608695652175, 0.07732142857142857, 0.0]\n"
     ]
    }
   ],
   "source": [
    "s_deleted_T = [\"\".join(row).replace(\" \", \"\") for row in s_deleted_TD]\n",
    "n_errors_total = [0] * T\n",
    "n_remaining_total = [sum(c != \" \" for c in s_noised) for s_noised in s_deleted_T]\n",
    "t_curr = 0\n",
    "for _ in range(1000):\n",
    "    for t_noise, s_noised in zip(t_T, s_deleted_T):\n",
    "        n_remaining = sum(c != \" \" for c in s_noised)\n",
    "        n_error = int(np.random.exponential(scale=n_remaining / 3) * np.sqrt((1 - t_noise) * np.sqrt(t_noise)))\n",
    "        n_errors_total[t_curr] += n_error\n",
    "        t_curr += 1\n",
    "        t_curr %= T\n",
    "        # print(n_error)\n",
    "n_errors_total = (np.array(n_errors_total) / 1000).tolist()\n",
    "print(n_errors_total)\n",
    "print(n_remaining_total)\n",
    "print([e / r if r > 0 else 0 for e, r in zip(n_errors_total, n_remaining_total)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2d3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2013-2022 Kyle Gorman\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the\n",
    "# \"Software\"), to deal in the Software without restriction, including\n",
    "# without limitation the rights to use, copy, modify, merge, publish,\n",
    "# distribute, sublicense, and/or sell copies of the Software, and to\n",
    "# permit persons to whom the Software is furnished to do so, subject to\n",
    "# the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included\n",
    "# in all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n",
    "# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n",
    "# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n",
    "# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n",
    "# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n",
    "# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"Levenshtein distance computation.\n",
    "\n",
    "The algorithm for computing the dynamic programming table used has been\n",
    "discovered many times, but is described most clearly in:\n",
    "\n",
    "R.A. Wagner & M.J. Fischer. 1974. The string-to-string correction\n",
    "problem. Journal of the ACM, 21(1): 168-173.\n",
    "\n",
    "Wagner & Fischer also describe an algorithm (\"Algorithm Y\") to find the\n",
    "alignment path (i.e., list of edit operations involved in the optimal\n",
    "alignment), but it is specified such that in fact it only generates\n",
    "one such path, whereas many such paths may exist, particularly when\n",
    "multiple edit operations have the same cost. For example, when all edit\n",
    "operations have the same cost, there are two equal-cost alignments of\n",
    "\"TGAC\" and \"GCAC\":\n",
    "\n",
    "     TGAC     TGxAC\n",
    "     ss==     d=i==\n",
    "     GCAC     xGCAC\n",
    "\n",
    "However, all such paths can be generated efficiently, as follows. First,\n",
    "the dynamic programming table \"cells\" are defined as tuples of (partial\n",
    "cost, set of all operations reaching this cell with minimal cost). As a\n",
    "result, the completed table can be thought of as an unweighted, directed\n",
    "graph (or FSA). The bottom right cell (the one containing the Levenshtein\n",
    "distance) is the start state and the origin as end state. The set of arcs\n",
    "are the set of operations in each cell as arcs. (Many of the cells of the\n",
    "table, those which are not visited by any optimal alignment, are under\n",
    "the graph interpretation unconnected vertices, and can be ignored. Every\n",
    "path between the bottom right cell and the origin cell is an optimal\n",
    "alignment. These paths can be efficiently enumerated using breadth-first\n",
    "traversal. The trick here is that elements in deque must not only contain\n",
    "indices but also partial paths. Averaging over all such paths, we can\n",
    "come up with an estimate of the number of insertions, deletions, and\n",
    "substitutions involved as well; in the example above, we say S = 1 and\n",
    "D, I = 0.5.\n",
    "\n",
    "Thanks to Christoph Weidemann (ctw@cogsci.info), who added support for\n",
    "arbitrary cost functions.\"\"\"\n",
    "\n",
    "import collections\n",
    "import doctest\n",
    "import pprint\n",
    "\n",
    "\n",
    "# Default cost functions.\n",
    "\n",
    "\n",
    "def INSERTION(A, cost=1):\n",
    "  return cost\n",
    "\n",
    "\n",
    "def DELETION(A, cost=1):\n",
    "  return cost\n",
    "\n",
    "\n",
    "def SUBSTITUTION(A, B, cost=1):\n",
    "  return cost\n",
    "\n",
    "\n",
    "Trace = collections.namedtuple(\"Trace\", [\"cost\", \"ops\"])\n",
    "\n",
    "\n",
    "class WagnerFischer(object):\n",
    "\n",
    "    \"\"\"\n",
    "    An object representing a (set of) Levenshtein alignments between two\n",
    "    iterable objects (they need not be strings). The cost of the optimal\n",
    "    alignment is scored in `self.cost`, and all Levenshtein alignments can\n",
    "    be generated using self.alignments()`.\n",
    "\n",
    "    Basic tests:\n",
    "\n",
    "    >>> WagnerFischer(\"god\", \"gawd\").cost\n",
    "    2\n",
    "    >>> WagnerFischer(\"sitting\", \"kitten\").cost\n",
    "    3\n",
    "    >>> WagnerFischer(\"bana\", \"banananana\").cost\n",
    "    6\n",
    "    >>> WagnerFischer(\"bana\", \"bana\").cost\n",
    "    0\n",
    "    >>> WagnerFischer(\"banana\", \"angioplastical\").cost\n",
    "    11\n",
    "    >>> WagnerFischer(\"angioplastical\", \"banana\").cost\n",
    "    11\n",
    "    >>> WagnerFischer(\"Saturday\", \"Sunday\").cost\n",
    "    3\n",
    "\n",
    "    IDS tests:\n",
    "\n",
    "    >>> WagnerFischer(\"doytauvab\", \"doyvautab\").IDS() == {\"S\": 2.0}\n",
    "    True\n",
    "    >>> WagnerFischer(\"kitten\", \"sitting\").IDS() == {\"I\": 1.0, \"S\": 2.0}\n",
    "    True\n",
    "\n",
    "    Detect insertion vs. deletion:\n",
    "\n",
    "    >>> thesmalldog = \"the small dog\".split()\n",
    "    >>> thebigdog = \"the big dog\".split()\n",
    "    >>> bigdog = \"big dog\".split()\n",
    "    >>> sub_inf = lambda A, B: float(\"inf\")\n",
    "\n",
    "    # Deletion.\n",
    "    >>> wf = WagnerFischer(thebigdog, bigdog, substitution=sub_inf)\n",
    "    >>> wf.IDS() == {\"D\": 1.0}\n",
    "    True\n",
    "\n",
    "    # Insertion.\n",
    "    >>> wf = WagnerFischer(bigdog, thebigdog, substitution=sub_inf)\n",
    "    >>> wf.IDS() == {\"I\": 1.0}\n",
    "    True\n",
    "\n",
    "    # Neither.\n",
    "    >>> wf = WagnerFischer(thebigdog, thesmalldog, substitution=sub_inf)\n",
    "    >>> wf.IDS() == {\"I\": 1.0, \"D\": 1.0}\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    # Initializes pretty printer (shared across all class instances).\n",
    "    pprinter = pprint.PrettyPrinter(width=75)\n",
    "\n",
    "    def __init__(self, A, B, insertion=INSERTION, deletion=DELETION,\n",
    "                 substitution=SUBSTITUTION):\n",
    "        # Stores cost functions in a dictionary for programmatic access.\n",
    "        self.costs = {\"I\": insertion, \"D\": deletion, \"S\": substitution}\n",
    "        # Initializes table.\n",
    "        self.asz = len(A)\n",
    "        self.bsz = len(B)\n",
    "        self._table = [[None for _ in range(self.bsz + 1)] for\n",
    "                       _ in range(self.asz + 1)]\n",
    "        # From now on, all indexing done using self.__getitem__.\n",
    "        ## Fills in edges.\n",
    "        self[0][0] = Trace(0, {\"O\"})  # Start cell.\n",
    "        for i in range(1, self.asz + 1):\n",
    "            self[i][0] = Trace(self[i - 1][0].cost + self.costs[\"D\"](A[i - 1]),\n",
    "                               {\"D\"})\n",
    "        for j in range(1, self.bsz + 1):\n",
    "            self[0][j] = Trace(self[0][j - 1].cost + self.costs[\"I\"](B[j - 1]),\n",
    "                               {\"I\"})\n",
    "        ## Fills in rest.\n",
    "        for i in range(len(A)):\n",
    "            for j in range(len(B)):\n",
    "                # Always calculate all operation costs to detect ties.\n",
    "                costD = self[i][j + 1].cost + self.costs[\"D\"](A[i])\n",
    "                costI = self[i + 1][j].cost + self.costs[\"I\"](B[j])\n",
    "                \n",
    "                # Check for match first, as it is always the cheapest option.\n",
    "                if A[i] == B[j]:\n",
    "                    costM = self[i][j].cost + 0  # Match is free\n",
    "                    costS = float('inf')  # Don't consider substitution for identical chars\n",
    "                else:\n",
    "                    costM = float('inf')  # No match possible\n",
    "                    costS = self[i][j].cost + self.costs[\"S\"](A[i], B[j])\n",
    "                \n",
    "                # Find minimum cost among all operations.\n",
    "                min_val = min(costD, costI, costM, costS)\n",
    "                trace = Trace(min_val, set())\n",
    "                \n",
    "                # Adds _all_ operations matching minimum value.\n",
    "                if costD == min_val:\n",
    "                    trace.ops.add(\"D\")\n",
    "                if costI == min_val:\n",
    "                    trace.ops.add(\"I\")\n",
    "                if costM == min_val:\n",
    "                    trace.ops.add(\"M\")\n",
    "                if costS == min_val:\n",
    "                    trace.ops.add(\"S\")\n",
    "                    \n",
    "                self[i + 1][j + 1] = trace\n",
    "        # Stores optimum cost as a property.\n",
    "        self.cost = self[-1][-1].cost\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.pprinter.pformat(self._table)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for row in self._table:\n",
    "            yield row\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Returns the i-th row of the table, which is a list and so\n",
    "        can be indexed. Therefore, e.g.,  self[2][3] == self._table[2][3]\n",
    "        \"\"\"\n",
    "        return self._table[i]\n",
    "\n",
    "    # Stuff for generating alignments.\n",
    "\n",
    "    def _stepback(self, i, j, trace, path_back):\n",
    "        \"\"\"\n",
    "        Given a cell location (i, j) and a Trace object trace, generate\n",
    "        all traces they point back to in the table\n",
    "        \"\"\"\n",
    "        for op in trace.ops:\n",
    "            if op == \"M\":\n",
    "                yield i - 1, j - 1, self[i - 1][j - 1], path_back + [\"M\"]\n",
    "            elif op == \"I\":\n",
    "                yield i, j - 1, self[i][j - 1], path_back + [\"I\"]\n",
    "            elif op == \"D\":\n",
    "                yield i - 1, j, self[i - 1][j], path_back + [\"D\"]\n",
    "            elif op == \"S\":\n",
    "                yield i - 1, j - 1, self[i - 1][j - 1], path_back + [\"S\"]\n",
    "            elif op == \"O\":\n",
    "                return  # Origin cell, so we\"re done.\n",
    "            else:\n",
    "                raise ValueError(\"Unknown op {!r}\".format(op))\n",
    "\n",
    "    def alignments(self):\n",
    "        \"\"\"\n",
    "        Generate all alignments with optimal-cost via breadth-first\n",
    "        traversal of the graph of all optimal-cost (reverse) paths\n",
    "        implicit in the dynamic programming table\n",
    "        \"\"\"\n",
    "        # Each cell of the queue is a tuple of (i, j, trace, path_back)\n",
    "        # where i, j is the current index, trace is the trace object at\n",
    "        # this cell, and path_back is a reversed list of edit operations\n",
    "        # which is initialized as an empty list.\n",
    "        queue = collections.deque(self._stepback(self.asz, self.bsz,\n",
    "                                                 self[-1][-1], []))\n",
    "        while queue:\n",
    "            (i, j, trace, path_back) = queue.popleft()\n",
    "            if trace.ops == {\"O\"}:\n",
    "                # We have reached the origin, the end of a reverse path, so\n",
    "                # yield the list of edit operations in reverse.\n",
    "                yield path_back[::-1]\n",
    "                continue\n",
    "            queue.extend(self._stepback(i, j, trace, path_back))\n",
    "\n",
    "    def IDS(self):\n",
    "        \"\"\"\n",
    "        Estimates insertions, deletions, and substitution _count_ (not\n",
    "        costs). Non-integer values arise when there are multiple possible\n",
    "        alignments with the same cost.\n",
    "        \"\"\"\n",
    "        npaths = 0\n",
    "        opcounts = collections.Counter()\n",
    "        for alignment in self.alignments():\n",
    "            # Counts edit types for this path, ignoring \"M\" (which is free).\n",
    "            opcounts += collections.Counter(op for op in alignment if op != \"M\")\n",
    "            npaths += 1\n",
    "        # Averages over all paths.\n",
    "        return collections.Counter({o: c / npaths for (o, c) in\n",
    "                                    opcounts.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df7a9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 alignments found\n",
      "IIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
      "12 alignments found\n",
      "IIIIIIIIIIIIIIIMIIIIIMIIMIIIII\n",
      "IIIIIMIIIIIIIIIIIIIIIMIIMIIIII\n",
      "IIIIIIIIIIIIIIIMIIIMIIIIMIIIII\n",
      "IIIIIMIIIIIIIIIIIIIMIIIIMIIIII\n",
      "IIIIIIIIIIIIIIIMIMIIIIIIMIIIII\n",
      "IIIIIMIIIIIIIIIIIMIIIIIIMIIIII\n",
      "IIIIIMIIIIIMIIIIIIIIIIIIMIIIII\n",
      "IIIIIMIIIMIIIIIIIIIIIIIIMIIIII\n",
      "IIIIIMIMIIIIIIIIIIIIIIIIMIIIII\n",
      "IIIIIMIIIIIMIIMIIIIIIIIIIIIIII\n",
      "IIIIIMIIIMIIIIMIIIIIIIIIIIIIII\n",
      "IIIIIMIMIIIIIIMIIIIIIIIIIIIIII\n",
      "26 alignments found\n",
      "IIIIIIIIIIIIIIIMIIMIIMIMMIIIII\n",
      "IIIIIMIIIIIIIIIIIIMIIMIMMIIIII\n",
      "IIIIIMIIMIIIIIIIIIIIIMIMMIIIII\n",
      "IIIIIIIIIIIIIIIMIIMMIIIMMIIIII\n",
      "IIIIIMIIIIIIIIIIIIMMIIIMMIIIII\n",
      "IIIIIMIIMIIIIIIIIIIMIIIMMIIIII\n",
      "IIIIIMIIMIIIIIIIIMIIIIIMMIIIII\n",
      "IIIIIMIIMIIMIIIIIIIIIIIMMIIIII\n",
      "IIIIIMIIMMIIIIIIIIIIIIIMMIIIII\n",
      "IIIIIIIIIIIIIIIMIIMIIMMIMIIIII\n",
      "IIIIIMIIIIIIIIIIIIMIIMMIMIIIII\n",
      "IIIIIMIIMIIIIIIIIIIIIMMIMIIIII\n",
      "IIIIIIIIIIIIIIIMIIMMIIMIMIIIII\n",
      "IIIIIMIIIIIIIIIIIIMMIIMIMIIIII\n",
      "IIIIIMIIMIIIIIIIIIIMIIMIMIIIII\n",
      "IIIIIMIIMIIIIIIIIMIIIIMIMIIIII\n",
      "IIIIIMIIMIIMIIIIIIIIIIMIMIIIII\n",
      "IIIIIMIIMMIIIIIIIIIIIIMIMIIIII\n",
      "IIIIIMIIMIIMIMIIIIIIIIIIMIIIII\n",
      "IIIIIMIIMMIIIMIIIIIIIIIIMIIIII\n",
      "IIIIIMIIMIIMMIIIIIIIIIIIMIIIII\n",
      "IIIIIMIIMMIIMIIIIIIIIIIIMIIIII\n",
      "IIIIIMIIMIIMIMMIIIIIIIIIIIIIII\n",
      "IIIIIMIIMMIIIMMIIIIIIIIIIIIIII\n",
      "IIIIIMIIMIIMMIMIIIIIIIIIIIIIII\n",
      "IIIIIMIIMMIIMIMIIIIIIIIIIIIIII\n",
      "22 alignments found\n",
      "IIIIIIIIIIIIIIIIIIIIIIMMMIIIII\n",
      "IIIIIIIIIIIIIMIIIIIIIIIMMIIIII\n",
      "IIIIIIIIIIIIMIIIIIIIIIIMMIIIII\n",
      "IIIMIIIIIIIIIIIIIIIIIIIMMIIIII\n",
      "IIMIIIIIIIIIIIIIIIIIIIIMMIIIII\n",
      "IIIIIIIIIIIIIMIIIIIIIIMIMIIIII\n",
      "IIIIIIIIIIIIMIIIIIIIIIMIMIIIII\n",
      "IIIMIIIIIIIIIIIIIIIIIIMIMIIIII\n",
      "IIMIIIIIIIIIIIIIIIIIIIMIMIIIII\n",
      "IIIIIIIIIIIIMMIIIIIIIIIIMIIIII\n",
      "IIIMIIIIIIIIIMIIIIIIIIIIMIIIII\n",
      "IIMIIIIIIIIIIMIIIIIIIIIIMIIIII\n",
      "IIIMIIIIIIIIMIIIIIIIIIIIMIIIII\n",
      "IIMIIIIIIIIIMIIIIIIIIIIIMIIIII\n",
      "IIMMIIIIIIIIIIIIIIIIIIIIMIIIII\n",
      "IIIIIIIIIIIIMMMIIIIIIIIIIIIIII\n",
      "IIIMIIIIIIIIIMMIIIIIIIIIIIIIII\n",
      "IIMIIIIIIIIIIMMIIIIIIIIIIIIIII\n",
      "IIIMIIIIIIIIMIMIIIIIIIIIIIIIII\n",
      "IIMIIIIIIIIIMIMIIIIIIIIIIIIIII\n",
      "IIMMIIIIIIIIIIMIIIIIIIIIIIIIII\n",
      "IIMMMIIIIIIIIIIIIIIIIIIIIIIIII\n",
      "16 alignments found\n",
      "IMIMIMIIMIMMMMIIIIIIMMIMMIMMMI\n",
      "IMMIIMIIMIMMMMIIIIIIMMIMMIMMMI\n",
      "IMIMIMIIMIMMMMIIMIIIIMIMMIMMMI\n",
      "IMMIIMIIMIMMMMIIMIIIIMIMMIMMMI\n",
      "IMIMIMIIMIMMMMIIMIIMIIIMMIMMMI\n",
      "IMMIIMIIMIMMMMIIMIIMIIIMMIMMMI\n",
      "IMIMIMIIMIMMMMIIMMIIIIIMMIMMMI\n",
      "IMMIIMIIMIMMMMIIMMIIIIIMMIMMMI\n",
      "IMIMIMIIMIMMMMIIIIIIMMMIMIMMMI\n",
      "IMMIIMIIMIMMMMIIIIIIMMMIMIMMMI\n",
      "IMIMIMIIMIMMMMIIMIIIIMMIMIMMMI\n",
      "IMMIIMIIMIMMMMIIMIIIIMMIMIMMMI\n",
      "IMIMIMIIMIMMMMIIMIIMIIMIMIMMMI\n",
      "IMMIIMIIMIMMMMIIMIIMIIMIMIMMMI\n",
      "IMIMIMIIMIMMMMIIMMIIIIMIMIMMMI\n",
      "IMMIIMIIMIMMMMIIMMIIIIMIMIMMMI\n",
      "4 alignments found\n",
      "MMMMIMIIMIMMMMMMMIIMMMIMIMMIMI\n",
      "MMMMIMIIMIMMMMMMMMIIMMIMIMMIMI\n",
      "MMMMIMIIMIMMMMMMMIIMMMMIIMMIMI\n",
      "MMMMIMIIMIMMMMMMMMIIMMMIIMMIMI\n",
      "4 alignments found\n",
      "MMIIMMMMMIIMMMMMIIMMMIIMMMIIMI\n",
      "MMIIMMMMMMIIMMMMIIMMMIIMMMIIMI\n",
      "MMIIMMMMMIIMMMMMIIMMMIMIMMIIMI\n",
      "MMIIMMMMMMIIMMMMIIMMMIMIMMIIMI\n",
      "4 alignments found\n",
      "MMMMMMMMMMMMIMMMIMMMMMIMMIIMMM\n",
      "MMMMMMMMMMMMMIMMIMMMMMIMMIIMMM\n",
      "MMMMMMMMMMMMIMMMIMMMMMMIMIIMMM\n",
      "MMMMMMMMMMMMMIMMIMMMMMMIMIIMMM\n",
      "4 alignments found\n",
      "MMIMMMMMMIMMIIMMMIMMMMIMIIMMMM\n",
      "MMMIMMMMMIMMIIMMMIMMMMIMIIMMMM\n",
      "MMIMMMMMMIMMIIMMMIMMMMMIIIMMMM\n",
      "MMMIMMMMMIMMIIMMMIMMMMMIIIMMMM\n",
      "2 alignments found\n",
      "IMMMIMMIIMMMMMMIIMMMIMMMMMMMMM\n",
      "IMMMIMMMIIMMMMMIIMMMIMMMMMMMMM\n",
      "2 alignments found\n",
      "IMMMMMMMMMMMIMMMMMMMMMMMMMMMMM\n",
      "IMMMMMMMMMMMMIMMMMMMMMMMMMMMMM\n",
      "1 alignments found\n",
      "MMMMMMMMMMMMMMMMMMMMMMMMMMMMMM\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(s_deleted_T)):\n",
    "    s_noised = s_deleted_T[i].replace(\" \", \"\")\n",
    "    alignments = list(WagnerFischer(s_noised, s).alignments())\n",
    "    print(len(alignments), \"alignments found\")\n",
    "    for a in alignments:\n",
    "    #     s_print, s_noised_print = \"\", \"\"\n",
    "    #     s_pt, s_noised_pt = 0, 0\n",
    "    #     for op in a:\n",
    "    #         if op == \"M\":\n",
    "    #             s_print += s[s_pt]\n",
    "    #             s_noised_print += s_noised[s_noised_pt]\n",
    "    #             s_pt += 1\n",
    "    #             s_noised_pt += 1\n",
    "    #         elif op == \"I\":\n",
    "    #             s_print += s[s_pt]\n",
    "    #             s_noised_print += \" \"\n",
    "    #             s_pt += 1\n",
    "    #         elif op == \"D\":\n",
    "    #             s_print += \" \"\n",
    "    #             s_noised_print += s_noised[s_noised_pt]\n",
    "    #             s_noised_pt += 1\n",
    "    #         elif op == \"S\":\n",
    "    #             s_print += s[s_pt]\n",
    "    #             s_noised_print += s_noised[s_noised_pt]\n",
    "    #             s_pt += 1\n",
    "    #             s_noised_pt += 1\n",
    "    #         else:\n",
    "    #             raise ValueError(\"Unknown op {!r}\".format(op))\n",
    "    #     print(s_noised_print)\n",
    "        print(\"\".join(a))\n",
    "    #     print(s_print)\n",
    "    #     print()\n",
    "    # print(\"=\" * D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

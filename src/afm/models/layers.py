# Transformer layers, embedding layers, etc. any NN-type stuff
# These are all generic layers whose inputs and outputs have no semantic meaning a priori
# Make sure to use flex attention for ...batch sizes at varying times and lengths
